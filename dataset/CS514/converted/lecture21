compsci 514: algorithms for data science  Andrew McGregor  Lecture 21  0  
summary  Computing the SVD/eigendecomposition • Eﬃcient algorithms for SVD/eigendecomposition. • High level: a glimpse into fast methods for linear algebraic  computation, which are workhorses behind data science.  1  
efficient eigendecomposition and svd  We have talked about the eigendecomposition and SVD as ways to compress data, to embed entities like words and documents, to compress/cluster non-linearly separable data.  How eﬃcient are these techniques? Can they be run on massive  datasets?  2  
power method  Power Method: The most fundamental iterative method for approximate SVD/eigendecomposition. Applies to computing k = 1 eigenvectors, but can be generalized to larger k. Goal: Given symmetric A ∈ Rd×d , with eigendecomposition A = VΛVT , ﬁnd (cid:126)z which is an approximation to the top eigenvector (cid:126)v1 of A.  3  
power method  Power Method: The most fundamental iterative method for approximate SVD/eigendecomposition. Applies to computing k = 1 eigenvectors, but can be generalized to larger k. Goal: Given symmetric A ∈ Rd×d , with eigendecomposition A = VΛVT , ﬁnd (cid:126)z which is an approximation to the top eigenvector (cid:126)v1 of A. • Initialize: Choose (cid:126)z (0) randomly. E.g. (cid:126)z (0)(i) ∼ N (0, 1). • For i = 1, . . . , t • (cid:126)z (i) := A · (cid:126)z (i−1) • (cid:126)zi := (cid:126)z (i) (cid:107)(cid:126)z (i)(cid:107)2 Return (cid:126)zt  3  
power method  4  
power method  4  
power method  4  
power method analysis  Write (cid:126)z (0) in A’s eigenvector basis:  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd .  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  5  
power method analysis  Write (cid:126)z (0) in A’s eigenvector basis:  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd .  Update step: (cid:126)z (i) = A · (cid:126)z (i−1) = VΛVT · (cid:126)z (i−1) (then normalize)  VT (cid:126)z (0) =  ΛVT (cid:126)z (0) =  (cid:126)z (1) = VΛVT · (cid:126)z (0) =  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  5  
power method analysis  Claim 1 : Writing (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd ,  (cid:126)z (1) = c1 · λ1(cid:126)v1 + c2 · λ2(cid:126)v2 + . . . + cd · λd (cid:126)vd .  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  6  
power method analysis  Claim 1 : Writing (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd ,  (cid:126)z (1) = c1 · λ1(cid:126)v1 + c2 · λ2(cid:126)v2 + . . . + cd · λd (cid:126)vd .  (cid:126)z (2) = A(cid:126)z (1) = VΛVT (cid:126)z (1) =  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  6  
power method analysis  Claim 1 : Writing (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd ,  (cid:126)z (1) = c1 · λ1(cid:126)v1 + c2 · λ2(cid:126)v2 + . . . + cd · λd (cid:126)vd .  (cid:126)z (2) = A(cid:126)z (1) = VΛVT (cid:126)z (1) =  Claim 2:  (cid:126)z (t) = c1 · λt  d (cid:126)vd .  1(cid:126)v1 + c2 · λt  2(cid:126)v2 + . . . + cd · λt  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  6  
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 0c1c2c3c4c5c6c7c8c9c10-0.8-0.6-0.4-0.200.20.4
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 0c1c2c3c4c5c6c7c8c9c10-0.8-0.6-0.4-0.200.20.4
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 1c1c2c3c4c5c6c7c8c9c10-0.6-0.4-0.200.20.40.60.8
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 2c1c2c3c4c5c6c7c8c9c10-0.4-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 3c1c2c3c4c5c6c7c8c9c10-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 4c1c2c3c4c5c6c7c8c9c10-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 5c1c2c3c4c5c6c7c8c9c10-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 6c1c2c3c4c5c6c7c8c9c10-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 7c1c2c3c4c5c6c7c8c9c10-0.200.20.40.60.81
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 8c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 9c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 10c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 11c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  7  Iteration 12c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method convergence  After t iterations, we have ‘powered’ up the eigenvalues, making the component in the direction of v1 much larger, relative to the other components. (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  d (cid:126)vd  When will convergence be slow?  7  Iteration 13c1c2c3c4c5c6c7c8c9c1000.10.20.30.40.50.60.70.80.91
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 0c1c2c3c4c5c6c7c8c9c10-0.6-0.4-0.200.20.40.6
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 0c1c2c3c4c5c6c7c8c9c10-0.6-0.4-0.200.20.40.6
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 1c1c2c3c4c5c6c7c8c9c10-0.3-0.2-0.100.10.20.30.40.50.60.7
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 2c1c2c3c4c5c6c7c8c9c10-0.2-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 3c1c2c3c4c5c6c7c8c9c10-0.2-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 4c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 5c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 6c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 7c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 8c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 9c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 10c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 11c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 12c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method slow convergence  Slow Case: A has eigenvalues: λ1 = 1, λ2 = .99, λ3 = .9, λ4 = .8, . . .  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt  d (cid:126)vd  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  8  Iteration 13c1c2c3c4c5c6c7c8c9c10-0.100.10.20.30.40.50.60.70.8
power method convergence rate  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1  |λ1|  .  e · |λ1|t?  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
power method convergence rate  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1  |λ1|  .  e · |λ1|t? 1/γ.  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
power method convergence rate  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1 How many iterations t does it take to have |λ2|t ≤ δ · |λ1|t?  1(cid:126)v1 + c2λt  |λ1|  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  .  e · |λ1|t? 1/γ.  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
power method convergence rate  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1 e · |λ1|t? 1/γ. How many iterations t does it take to have |λ2|t ≤ δ · |λ1|t? ln(1/δ)  1(cid:126)v1 + c2λt  |λ1|  .  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  .  γ  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
power method convergence rate  1(cid:126)v1 + c2λt  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1 e · |λ1|t? 1/γ. How many iterations t does it take to have |λ2|t ≤ δ · |λ1|t? ln(1/δ) Will have for all i > 1, |λi|t ≤ |λ2|t ≤ δ · |λ1|t.  |λ1|  .  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  .  γ  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
power method convergence rate  1(cid:126)v1 + c2λt  2(cid:126)v2 + . . . + cd λt  2(cid:126)vd  .  |λ1|  (cid:126)z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd =⇒ (cid:126)z (t) = c1λt |λ1|−|λ2| Write |λ2| = (1 − γ)|λ1| for ‘gap’ γ = How many iterations t does it take to have |λ2|t ≤ 1 e · |λ1|t? 1/γ. How many iterations t does it take to have |λ2|t ≤ δ · |λ1|t? ln(1/δ) Will have for all i > 1, |λi|t ≤ |λ2|t ≤ δ · |λ1|t. How small must we set δ to ensure that c1λt components and so (cid:126)z (t) is very close to (cid:126)v1?  1 dominates all other  γ  .  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  9  
random initialization  Claim: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, for all i:  Corollary:  max  j  (cid:12)(cid:12)(cid:12)(cid:12) cj  c1  O(1/d 2) ≤ |ci| ≤ O(log d)  (cid:12)(cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  10  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:126)z (t) :=  c1λt (cid:107)c1λt  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:126)z (t) :=  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤  c1λt (cid:107)c1λt  (cid:13)(cid:13)(cid:13)(cid:13) c1λt  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2 d (cid:126)vd  (cid:107)c1λt  1(cid:126)v1(cid:107)2  =⇒  (cid:13)(cid:13)(cid:13)(cid:13)2  − (cid:126)v1  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:126)z (t) :=  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2 d (cid:126)vd  c1λt (cid:107)c1λt  (cid:13)(cid:13)(cid:13)(cid:13) c1λt  =⇒  (cid:13)(cid:13)(cid:13)(cid:13)2  − (cid:126)v1  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤  (cid:13)(cid:13)(cid:13)(cid:13) c2λt  2 c1λt 1  =  (cid:126)v2 + . . . +  1(cid:126)v1(cid:107)2 (cid:126)vd  (cid:13)(cid:13)(cid:13)(cid:13)2  (cid:107)c1λt cd λt d c1λt 1  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  (cid:126)z (t) :=  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤  (cid:13)(cid:13)(cid:13)(cid:13) c2λt  2 c1λt 1  =  (cid:126)v2 + . . . +  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2 d (cid:126)vd  c1λt (cid:107)c1λt  (cid:13)(cid:13)(cid:13)(cid:13) c1λt  1(cid:126)v1(cid:107)2 (cid:126)vd  (cid:13)(cid:13)(cid:13)(cid:13)2  (cid:107)c1λt cd λt d c1λt 1  ≤  =⇒  (cid:13)(cid:13)(cid:13)(cid:13)2 (cid:12)(cid:12)(cid:12)(cid:12) + . . . +  − (cid:126)v1  (cid:12)(cid:12)(cid:12)(cid:12) c2λt  2 c1λt 1  (cid:12)(cid:12)(cid:12)(cid:12) cd λt  d c1λt 1  (cid:12)(cid:12)(cid:12)(cid:12)  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  (cid:126)z (t) :=  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤  (cid:13)(cid:13)(cid:13)(cid:13) c2λt  2 c1λt 1  =  (cid:126)v2 + . . . +  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2 d (cid:126)vd  c1λt (cid:107)c1λt  (cid:13)(cid:13)(cid:13)(cid:13) c1λt  1(cid:126)v1(cid:107)2 (cid:126)vd  (cid:13)(cid:13)(cid:13)(cid:13)2  (cid:107)c1λt cd λt d c1λt 1  ≤  =⇒  (cid:13)(cid:13)(cid:13)(cid:13)2 (cid:12)(cid:12)(cid:12)(cid:12) + . . . +  − (cid:126)v1  (cid:12)(cid:12)(cid:12)(cid:12) c2λt  2 c1λt 1  (cid:12)(cid:12)(cid:12)(cid:12) cd λt  d c1λt 1  (cid:12)(cid:12)(cid:12)(cid:12) ≤ δ · O(d 2 log d) · d  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
random initialization  Claim 1: When z (0) is chosen with random Gaussian entries, writing z (0) = c1(cid:126)v1 + c2(cid:126)v2 + . . . + cd (cid:126)vd , with very high probability, maxj  (cid:12)(cid:12)(cid:12) ≤ O(d 2 log d).  (cid:12)(cid:12)(cid:12) cj  c1  Claim 2: For gap γ =  |λ1|−|λ2|  |λ1|  , and t = ln(1/δ)  γ  ,  (cid:12)(cid:12)(cid:12) λt  i λt 1  (cid:12)(cid:12)(cid:12) ≤ δ for all i.  (cid:126)z (t) :=  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤  (cid:13)(cid:13)(cid:13)(cid:13) c2λt  2 c1λt 1  c1λt (cid:107)c1λt  (cid:13)(cid:13)(cid:13)(cid:13) c1λt (cid:16)   d 3 log d  1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt 1(cid:126)v1 + . . . + cd λt  d (cid:126)vd d (cid:126)vd(cid:107)2 d (cid:126)vd  − (cid:126)v1  (cid:13)(cid:13)(cid:13)(cid:13)2  (cid:12)(cid:12)(cid:12)(cid:12) c2λt  1(cid:126)v1(cid:107)2 (cid:126)vd  (cid:107)c1λt cd λt d c1λt 1 gives (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤ .  2 c1λt 1  ≤  (cid:17)  =⇒  (cid:13)(cid:13)(cid:13)(cid:13)2 (cid:12)(cid:12)(cid:12)(cid:12) + . . . +  =  (cid:126)v2 + . . . +  Setting δ = O  (cid:12)(cid:12)(cid:12)(cid:12) cd λt  d c1λt 1  (cid:12)(cid:12)(cid:12)(cid:12) ≤ δ · O(d 2 log d) · d  A ∈ Rd×d : input matrix with eigendecomposition A = VΛVT . (cid:126)v1: top eigen- vector, being computed, (cid:126)z (i): iterate at step i, converging to (cid:126)v1.  11  
power method theorem  Theorem (Basic Power Method Convergence)  |λ1|−|λ2|  |λ1|  be the relative gap between the ﬁrst and second  Let γ = eigenvalues. If Power Method is initialized with a random Gaussian vector (cid:126)v (0) then, with high probability, after t = O steps:  (cid:16) ln(d/)  (cid:17)  γ  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤ .  12  
power method theorem  Theorem (Basic Power Method Convergence)  |λ1|−|λ2|  |λ1|  be the relative gap between the ﬁrst and second  Let γ = eigenvalues. If Power Method is initialized with a random Gaussian vector (cid:126)v (0) then, with high probability, after t = O steps:  (cid:16) ln(d/)  (cid:17)  γ  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤ .  (cid:19)  (cid:18)  (cid:19)  O  nnz(X) · ln(d/)  γ  ·  = O  nd · ln(d/)  γ  Total runtime: O(t) matrix-vector multiplications. If A = XT X:  (cid:18)  .  12  
power method theorem  Theorem (Basic Power Method Convergence)  |λ1|−|λ2|  |λ1|  be the relative gap between the ﬁrst and second  Let γ = eigenvalues. If Power Method is initialized with a random Gaussian vector (cid:126)v (0) then, with high probability, after t = O steps:  (cid:16) ln(d/)  (cid:17)  γ  (cid:107)(cid:126)z (t) − (cid:126)v1(cid:107)2 ≤ .  Total runtime: O(t) matrix-vector multiplications. If A = XT X:  (cid:18)  (cid:19)  (cid:18)  (cid:19)  .  nnz(X) · ln(d/)  ·  O  = O  nd · ln(d/)  γ  γ  (cid:16) ln(d/)√  (cid:17)  Can actually do it in O methods” such as Lanczos method and Arnoldi method.  iterations using “Krylov subspace  γ  12  
finding second (etc.) eigenvector  • If A has eigenvectors v1, . . . , vn with eigenvalues λ1, . . . , λn  (|λ1| ≥ . . . ≥ |λn|) then  B = A − λ1v1v T  1  has eigenvectors v2, . . . , vn, v1 with eigenvectors λ2, . . . , λn, 0  • Hence, to ﬁnd the second eigenvector of A, just apply the  previous method to B.  13  
connection to random walks  Consider a random walk on a graph G with adjacency matrix A.  14  
connection to random walks  Consider a random walk on a graph G with adjacency matrix A.  At each step, move to a random vertex, chosen uniformly at random from the neighbors of the current vertex.  14  
connection to random walks  Consider a random walk on a graph G with adjacency matrix A.  14  
connection to random walks  Consider a random walk on a graph G with adjacency matrix A.  14  
connection to random walks  Consider a random walk on a graph G with adjacency matrix A.  14  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t)  i = Pr(walk at node i at step t).  15  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0].  i = Pr(walk at node i at step t).  15  
connection to random walks  i = Pr(walk at node i at step t).  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0]. • Update:  Pr(walk at i at step t) =  (cid:88)  j∈neigh(i)  Pr(walk at j at step t-1) ·  1  degree(j)  15  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0]. • Update:  i = Pr(walk at node i at step t).  (cid:88)  j∈neigh(i) = (cid:126)z T (cid:126)p(t−1)  Pr(walk at i at step t) =  Pr(walk at j at step t-1) ·  1  degree(j)  where (cid:126)z(j) =  degree(j) for all j ∈ neigh(i), (cid:126)z(j) = 0 for all j /∈ neigh(i).  1  15  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0]. • Update:  i = Pr(walk at node i at step t).  (cid:88)  j∈neigh(i) = (cid:126)z T (cid:126)p(t−1)  Pr(walk at i at step t) =  Pr(walk at j at step t-1) ·  1  degree(j)  where (cid:126)z(j) =  degree(j) for all j ∈ neigh(i), (cid:126)z(j) = 0 for all j /∈ neigh(i).  1  • (cid:126)z is the i th row of the right normalized adjacency matrix AD−1.  15  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0]. • Update:  i = Pr(walk at node i at step t).  (cid:88)  j∈neigh(i) = (cid:126)z T (cid:126)p(t−1)  Pr(walk at i at step t) =  Pr(walk at j at step t-1) ·  1  degree(j)  where (cid:126)z(j) =  degree(j) for all j ∈ neigh(i), (cid:126)z(j) = 0 for all j /∈ neigh(i).  1  • (cid:126)z is the i th row of the right normalized adjacency matrix AD−1. • (cid:126)p(t) = AD−1(cid:126)p(t−1)  15  
connection to random walks  Let (cid:126)p(t) ∈ Rn have i th entry (cid:126)p(t) • Initialize: (cid:126)p(0) = [1, 0, 0, . . . , 0]. • Update:  i = Pr(walk at node i at step t).  (cid:88)  j∈neigh(i) = (cid:126)z T (cid:126)p(t−1)  Pr(walk at i at step t) =  Pr(walk at j at step t-1) ·  1  degree(j)  where (cid:126)z(j) =  degree(j) for all j ∈ neigh(i), (cid:126)z(j) = 0 for all j /∈ neigh(i).  1  • (cid:126)z is the i th row of the right normalized adjacency matrix AD−1. • (cid:126)p(t) = AD−1(cid:126)p(t−1) = AD−1AD−1 . . . AD−1  (cid:126)p(0)  (cid:124)  (cid:123)(cid:122)  t times  (cid:125)  15  
random walking as power method  Claim: After t steps, the probability that a random walk is at node i is given by the i th entry of  (cid:126)p(t) = AD−1AD−1 . . . AD−1  (cid:124)  (cid:123)(cid:122)  t times  (cid:125)  (cid:126)p(0).  16  
random walking as power method  Claim: After t steps, the probability that a random walk is at node i is given by the i th entry of  (cid:126)p(t) = AD−1AD−1 . . . AD−1  (cid:126)p(0).  (cid:124)  (cid:125)  D−1/2(cid:126)p(t) = (D−1/2AD−1/2)(D−1/2AD−1/2) . . . (D−1/2AD−1/2)  (D−1/2(cid:126)p(0)).  (cid:124)  (cid:125)  (cid:123)(cid:122) (cid:123)(cid:122)  t times  t times  16  
random walking as power method  Claim: After t steps, the probability that a random walk is at node i is given by the i th entry of  (cid:126)p(t) = AD−1AD−1 . . . AD−1  (cid:126)p(0).  (cid:124)  (cid:125)  (cid:123)(cid:122) (cid:123)(cid:122)  t times  t times  D−1/2(cid:126)p(t) = (D−1/2AD−1/2)(D−1/2AD−1/2) . . . (D−1/2AD−1/2)  (D−1/2(cid:126)p(0)).  (cid:124)  (cid:125)  • D−1/2(cid:126)p(t) is exactly what would obtained by applying t/2 iterations of  power method to D−1/2(cid:126)p(0)!  16  
random walking as power method  Claim: After t steps, the probability that a random walk is at node i is given by the i th entry of  (cid:126)p(t) = AD−1AD−1 . . . AD−1  (cid:126)p(0).  (cid:124)  (cid:125)  (cid:123)(cid:122) (cid:123)(cid:122)  t times  t times  (cid:125)  D−1/2(cid:126)p(t) = (D−1/2AD−1/2)(D−1/2AD−1/2) . . . (D−1/2AD−1/2)  (D−1/2(cid:126)p(0)).  (cid:124)  • D−1/2(cid:126)p(t) is exactly what would obtained by applying t/2 iterations of  power method to D−1/2(cid:126)p(0)!  • Will converge to the top eigenvector of the normalized adjacency  matrix D−1/2AD−1/2. Stationary distribution.  16  
random walking as power method  Claim: After t steps, the probability that a random walk is at node i is given by the i th entry of  (cid:126)p(t) = AD−1AD−1 . . . AD−1  (cid:126)p(0).  (cid:124)  (cid:125)  (cid:123)(cid:122) (cid:123)(cid:122)  t times  t times  (cid:124)  D−1/2(cid:126)p(t) = (D−1/2AD−1/2)(D−1/2AD−1/2) . . . (D−1/2AD−1/2)  (D−1/2(cid:126)p(0)).  (cid:125)  • D−1/2(cid:126)p(t) is exactly what would obtained by applying t/2 iterations of  power method to D−1/2(cid:126)p(0)!  • Will converge to the top eigenvector of the normalized adjacency  matrix D−1/2AD−1/2. Stationary distribution.  • Like the power method, the time a random walk takes to converge to  its stationary distribution (mixing time) is dependent on the gap between the top two eigenvalues of D−1/2AD−1/2. The spectral gap.  16  

compsci 514: algorithms for data science  Andrew McGregor  Lecture 24  0  
summary  Last Class: • Analysis of gradient descent for optimizing convex functions.  This Class: • Introduction to convex sets and projection functions. • (The same) analysis of projected gradient descent for optimizing under  convex functions under (convex) constraints.  • Online learning, regret, and online gradient descent. • Application to stochastic gradient descent.  1  
constrained convex optimization  Often want to perform convex optimization with convex constraints.  (cid:126)θ∗ = arg min (cid:126)θ∈S  f ((cid:126)θ),  where S is a convex set.  2  
constrained convex optimization  Often want to perform convex optimization with convex constraints.  (cid:126)θ∗ = arg min (cid:126)θ∈S  f ((cid:126)θ),  where S is a convex set.  Deﬁnition – Convex Set: A set S ⊆ Rd is convex if and only if, for any (cid:126)θ1, (cid:126)θ2 ∈ S and λ ∈ [0, 1]: (1 − λ)(cid:126)θ1 + λ · (cid:126)θ2 ∈ S  2  
constrained convex optimization  Often want to perform convex optimization with convex constraints.  (cid:126)θ∗ = arg min (cid:126)θ∈S  f ((cid:126)θ),  where S is a convex set.  Deﬁnition – Convex Set: A set S ⊆ Rd is convex if and only if, for any (cid:126)θ1, (cid:126)θ2 ∈ S and λ ∈ [0, 1]: (1 − λ)(cid:126)θ1 + λ · (cid:126)θ2 ∈ S  For any convex set let PS(·) denote the projection function onto S:  PS((cid:126)y ) = arg min  (cid:126)θ∈S  (cid:107)(cid:126)θ − (cid:126)y(cid:107)2  2  
constrained convex optimization  Often want to perform convex optimization with convex constraints.  (cid:126)θ∗ = arg min (cid:126)θ∈S  f ((cid:126)θ),  where S is a convex set.  Deﬁnition – Convex Set: A set S ⊆ Rd is convex if and only if, for any (cid:126)θ1, (cid:126)θ2 ∈ S and λ ∈ [0, 1]: (1 − λ)(cid:126)θ1 + λ · (cid:126)θ2 ∈ S  For any convex set let PS(·) denote the projection function onto S:  PS((cid:126)y ) = arg min  (cid:126)θ∈S  (cid:107)(cid:126)θ − (cid:126)y(cid:107)2  • For S = {(cid:126)θ ∈ Rd : (cid:107)(cid:126)θ(cid:107)2 ≤ 1} what is PS((cid:126)y )?  2  
constrained convex optimization  Often want to perform convex optimization with convex constraints.  (cid:126)θ∗ = arg min (cid:126)θ∈S  f ((cid:126)θ),  where S is a convex set.  Deﬁnition – Convex Set: A set S ⊆ Rd is convex if and only if, for any (cid:126)θ1, (cid:126)θ2 ∈ S and λ ∈ [0, 1]: (1 − λ)(cid:126)θ1 + λ · (cid:126)θ2 ∈ S  For any convex set let PS(·) denote the projection function onto S:  PS((cid:126)y ) = arg min  (cid:126)θ∈S  (cid:107)(cid:126)θ − (cid:126)y(cid:107)2  • For S = {(cid:126)θ ∈ Rd : (cid:107)(cid:126)θ(cid:107)2 ≤ 1} what is PS((cid:126)y )? • For S being a k dimensional subspace of Rd , what is PS((cid:126)y )?  2  
projected gradient descent  Projected Gradient Descent • Choose some initialization (cid:126)θ1 and set η = R √ • For i = 1, . . . , t − 1  G  i+1 = (cid:126)θi − η · (cid:126)∇f ((cid:126)θi )  • (cid:126)θ(out) • (cid:126)θi+1 = PS((cid:126)θ(out) i+1 ). • Return ˆθ = arg min(cid:126)θi  f ((cid:126)θi ).  .  t  3  
convex projections  Analysis of projected gradient descent is almost identifcal to gradient descent analysis!  4  
convex projections  Analysis of projected gradient descent is almost identifcal to gradient descent analysis! Just need to appeal to following geometric result:  Theorem – Projection to a convex set: For any convex set S ⊆ Rd , (cid:126)y ∈ Rd , and (cid:126)θ ∈ S,  (cid:107)PS((cid:126)y ) − (cid:126)θ(cid:107)2 ≤ (cid:107)(cid:126)y − (cid:126)θ(cid:107)2.  4  
projected gradient descent analysis  Theorem – Projected GD: For convex G -Lipschitz function f , and convex set S, Projected GD run with t ≥ R 2G 2 iterations, √ , and starting point within radius R of (cid:126)θ∗ = min(cid:126)θ∈S f ((cid:126)θ), η = R G outputs ˆθ satisfying:  2  t  f (ˆθ) ≤ f ((cid:126)θ∗) +   5  
projected gradient descent analysis  Theorem – Projected GD: For convex G -Lipschitz function f , and convex set S, Projected GD run with t ≥ R 2G 2 iterations, √ , and starting point within radius R of (cid:126)θ∗ = min(cid:126)θ∈S f ((cid:126)θ), η = R G outputs ˆθ satisfying:  2  t  f (ˆθ) ≤ f ((cid:126)θ∗) +   Recall: (cid:126)θ(out)  i+1 = (cid:126)θi − η · (cid:126)∇f ((cid:126)θi ) and (cid:126)θi+1 = PS((cid:126)θ(out) i+1 ).  5  
projected gradient descent analysis  Theorem – Projected GD: For convex G -Lipschitz function f , and convex set S, Projected GD run with t ≥ R 2G 2 iterations, √ , and starting point within radius R of (cid:126)θ∗ = min(cid:126)θ∈S f ((cid:126)θ), η = R G outputs ˆθ satisfying:  2  t  f (ˆθ) ≤ f ((cid:126)θ∗) +   Recall: (cid:126)θ(out) Step 1: For all i, f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ (cid:107)(cid:126)θi−θ∗(cid:107)2  i+1 = (cid:126)θi − η · (cid:126)∇f ((cid:126)θi ) and (cid:126)θi+1 = PS((cid:126)θ(out) i+1 ). i+1 −(cid:126)θ∗(cid:107)2  2−(cid:107)(cid:126)θ(out)  2  2η  + ηG 2 2 .  5  
projected gradient descent analysis  Theorem – Projected GD: For convex G -Lipschitz function f , and convex set S, Projected GD run with t ≥ R 2G 2 iterations, √ , and starting point within radius R of (cid:126)θ∗ = min(cid:126)θ∈S f ((cid:126)θ), η = R G outputs ˆθ satisfying:  2  t  f (ˆθ) ≤ f ((cid:126)θ∗) +   i+1 = (cid:126)θi − η · (cid:126)∇f ((cid:126)θi ) and (cid:126)θi+1 = PS((cid:126)θ(out) i+1 ). i+1 −(cid:126)θ∗(cid:107)2  Recall: (cid:126)θ(out) Step 1: For all i, f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ (cid:107)(cid:126)θi−θ∗(cid:107)2 Step 1.a: For all i, f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ (cid:107)(cid:126)θi−(cid:126)θ∗(cid:107)2  2η 2−(cid:107)(cid:126)θi+1−(cid:126)θ∗(cid:107)2 2η  2−(cid:107)(cid:126)θ(out)  2  + ηG 2 2 .  2  + ηG 2 2 .  5  
projected gradient descent analysis  Theorem – Projected GD: For convex G -Lipschitz function f , and convex set S, Projected GD run with t ≥ R 2G 2 iterations, √ , and starting point within radius R of (cid:126)θ∗ = min(cid:126)θ∈S f ((cid:126)θ), η = R G outputs ˆθ satisfying:  2  t  f (ˆθ) ≤ f ((cid:126)θ∗) +   i+1 = (cid:126)θi − η · (cid:126)∇f ((cid:126)θi ) and (cid:126)θi+1 = PS((cid:126)θ(out) i+1 ). i+1 −(cid:126)θ∗(cid:107)2  2−(cid:107)(cid:126)θ(out)  Recall: (cid:126)θ(out) Step 1: For all i, f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ (cid:107)(cid:126)θi−θ∗(cid:107)2 Step 1.a: For all i, f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ (cid:107)(cid:126)θi−(cid:126)θ∗(cid:107)2 2η·t + ηG 2  (cid:80)t i=1 f ((cid:126)θi ) − f ((cid:126)θ∗) ≤ R 2  Step 2: 1 t  2η 2−(cid:107)(cid:126)θi+1−(cid:126)θ∗(cid:107)2 2η  + ηG 2 2 . 2 =⇒ Theorem.  2  2  + ηG 2 2 .  5  
online gradient descent  In reality many learning problems are online. • Websites optimize ads or recommendations to show users, given  continuous feedback from these users.  • Spam ﬁlters are incrementally updated and adapt as they see more  examples of spam over time.  • Face recognition systems, other classiﬁcation systems, learn from  mistakes over time.  6  
online gradient descent  In reality many learning problems are online. • Websites optimize ads or recommendations to show users, given  continuous feedback from these users.  • Spam ﬁlters are incrementally updated and adapt as they see more  examples of spam over time.  • Face recognition systems, other classiﬁcation systems, learn from  mistakes over time.  Want to minimize some global loss L((cid:126)θ, X) =(cid:80)n  i=1 (cid:96)((cid:126)θ, (cid:126)xi ), when data  points are presented in an online fashion (cid:126)x1, (cid:126)x2, . . . , (cid:126)xn (similar to streaming algorithms)  6  
online gradient descent  In reality many learning problems are online. • Websites optimize ads or recommendations to show users, given  continuous feedback from these users.  • Spam ﬁlters are incrementally updated and adapt as they see more  examples of spam over time.  • Face recognition systems, other classiﬁcation systems, learn from  mistakes over time.  Want to minimize some global loss L((cid:126)θ, X) =(cid:80)n  i=1 (cid:96)((cid:126)θ, (cid:126)xi ), when data  points are presented in an online fashion (cid:126)x1, (cid:126)x2, . . . , (cid:126)xn (similar to streaming algorithms)  Stochastic gradient descent is a special case: when data points are considered a random order for computational reasons.  6  
online optimization formal setup  Online Optimization: In place of a single function f , we see a diﬀerent objective function at each step:  f1, f2, . . . , ft : Rd → R  7  
online optimization formal setup  Online Optimization: In place of a single function f , we see a diﬀerent objective function at each step:  f1, f2, . . . , ft : Rd → R  • At each step, ﬁrst pick (play) a parameter vector (cid:126)θ(i). • Then are told fi and incur cost fi ((cid:126)θ(i)). i=1 fi ((cid:126)θ(i)).  • Goal: Minimize total cost(cid:80)t  7  
online optimization formal setup  Online Optimization: In place of a single function f , we see a diﬀerent objective function at each step:  f1, f2, . . . , ft : Rd → R  • At each step, ﬁrst pick (play) a parameter vector (cid:126)θ(i). • Then are told fi and incur cost fi ((cid:126)θ(i)). i=1 fi ((cid:126)θ(i)).  • Goal: Minimize total cost(cid:80)t  Our analysis will make no assumptions on how f1, . . . , ft are related to each other!  7  
online optimization example  Home pricing tools.  • Parameter vector (cid:126)θ(i): coeﬃcients of linear model at step i. • Functions f1, . . . , ft: fi ((cid:126)θ(i)) = ((cid:104)(cid:126)xi , (cid:126)θ(i)(cid:105) − pricei )2 revealed when  • Want to minimize total squared error(cid:80)t  homei is listed or sold.  classic least squares regression).  8  i=1 fi ((cid:126)θ(i)) (same as  
online optimization example  UI design via online optimization.  • Parameter vector (cid:126)θ(i): some encoding of the layout at step i. • Functions f1, . . . , ft: fi ((cid:126)θ(i)) = 1 if user does not click ‘add to (cid:80)t • Want to maximize number of purchases, i.e., minimize  cart’ and fi ((cid:126)θ(i)) = 0 if they do click.  i=1 fi ((cid:126)θ(i)).  9  
regret  In normal optimization, we seek ˆθ satisfying:  f (ˆθ) ≤ min (cid:126)θ  f ((cid:126)θ) + .  10  
regret  In normal optimization, we seek ˆθ satisfying:  f (ˆθ) ≤ min (cid:126)θ  f ((cid:126)θ) + .  In online optimization we will ask for the same.  t(cid:88)  i=1  fi ((cid:126)θ(i)) ≤ min (cid:126)θ  t(cid:88)  t(cid:88)  fi ((cid:126)θ) +  =  fi ((cid:126)θoﬀ ) +   i=1  i=1   is called the regret and /t is the average regret.  10  
regret  In normal optimization, we seek ˆθ satisfying:  f (ˆθ) ≤ min (cid:126)θ  f ((cid:126)θ) + .  In online optimization we will ask for the same.  t(cid:88)  i=1  fi ((cid:126)θ(i)) ≤ min (cid:126)θ  t(cid:88)  t(cid:88)  fi ((cid:126)θ) +  =  fi ((cid:126)θoﬀ ) +   i=1  i=1   is called the regret and /t is the average regret. • This error metric is a bit unusual: Comparing online solution to  best ﬁxed solution in hindsight.  can be negative!  10  
intuition check  What if for i = 1, . . . , t, fi (θ) = |θ − 1000| or fi (θ) = |θ + 1000| in an alternating pattern?  i=1 fi ((cid:126)θoﬀ ) + .  How small can the regret  be? (cid:80)t  i=1 fi ((cid:126)θ(i)) ≤(cid:80)t  11  
intuition check  How small can the regret  be? (cid:80)t  i=1 fi ((cid:126)θ(i)) ≤(cid:80)t  What if for i = 1, . . . , t, fi (θ) = |θ − 1000| or fi (θ) = |θ + 1000| in an alternating pattern?  i=1 fi ((cid:126)θoﬀ ) + . What if for i = 1, . . . , t, fi (θ) = |θ − 1000| or fi (θ) = |θ + 1000| in no particular pattern? How can any online learning algorithm hope to achieve small regret?  11  
online gradient descent  Assume that: • f1, . . . , ft are all convex. • Each fi is G -Lipschitz (i.e., (cid:107)(cid:126)∇fi ((cid:126)θ)(cid:107)2 ≤ G for all (cid:126)θ.) • (cid:107)(cid:126)θ(1) − (cid:126)θoﬀ (cid:107)2 ≤ R where θ(1) is the ﬁrst vector chosen.  12  
online gradient descent  Assume that: • f1, . . . , ft are all convex. • Each fi is G -Lipschitz (i.e., (cid:107)(cid:126)∇fi ((cid:126)θ)(cid:107)2 ≤ G for all (cid:126)θ.) • (cid:107)(cid:126)θ(1) − (cid:126)θoﬀ (cid:107)2 ≤ R where θ(1) is the ﬁrst vector chosen.  Online Gradient Descent • Pick some initial (cid:126)θ(1). • Set step size η = R √ • For i = 1, . . . , t  G  • Play (cid:126)θ(i) and incur cost fi ((cid:126)θ(i)). • (cid:126)θ(i+1) = (cid:126)θ(i) − η · (cid:126)∇fi ((cid:126)θ(i))  .  t  12  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  i=1  i=1  (cid:35)  √  ≤ RG  fi (θoﬀ )  t  13  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  fi (θoﬀ )  ≤ RG  √  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  (cid:35)  i=1  i=1  Upper bound on average regret goes to 0 and t → ∞.  13  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  fi (θoﬀ )  ≤ RG  √  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  (cid:35)  i=1  i=1  Upper bound on average regret goes to 0 and t → ∞. No assumptions on f1, . . . , ft!  13  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  fi (θoﬀ )  ≤ RG  √  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  (cid:35)  i=1  i=1  Upper bound on average regret goes to 0 and t → ∞. No assumptions on f1, . . . , ft! Step 1.1: For all i, ∇fi (θ(i))T (θ(i) − θoﬀ ) ≤ (cid:107)θ(i)−θoﬀ (cid:107)2  2−(cid:107)θ(i+1)−θoﬀ (cid:107)2 2η  + ηG 2 2  2  13  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  i=1  i=1  (cid:35)  fi (θoﬀ )  ≤ RG  √  t  Upper bound on average regret goes to 0 and t → ∞. No assumptions on f1, . . . , ft! Step 1.1: For all i, ∇fi (θ(i))T (θ(i) − θoﬀ ) ≤ (cid:107)θ(i)−θoﬀ (cid:107)2 Convexity =⇒ Step 1: For all i,  2−(cid:107)θ(i+1)−θoﬀ (cid:107)2 2η  + ηG 2 2  2  fi (θ(i)) − fi (θoﬀ ) ≤ (cid:107)θ(i) − θoﬀ (cid:107)2  2 − (cid:107)θ(i+1) − θoﬀ (cid:107)2  2  2η  +  ηG 2  2  .  13  
online gradient descent analysis  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  fi (θoﬀ )  ≤ RG  √  t  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  (cid:35)  i=1  i=1  Step 1: For all i, fi (θ(i)) − fi (θoﬀ ) ≤ (cid:107)θ(i)−θoﬀ (cid:107)2  2−(cid:107)θ(i+1)−θoﬀ (cid:107)2 2η  2  + ηG 2 2  14  
online gradient descent analysis  (cid:34) t(cid:88)  i=1  fi (θ(i)) − t(cid:88) (cid:35)  i=1  t(cid:88)  ≤  (cid:34) t(cid:88)  fi (θ(i)) − t(cid:88)  i=1  i=1  fi (θoﬀ )  Theorem – OGD on Convex Lipschitz Functions: For con- vex G -Lipschitz f1, . . . , ft, OGD initialized with starting point θ(1) √ within radius R of θoﬀ , using step size η = R , has regret bounded G by:  t  (cid:35)  √  t  ≤ RG  fi (θoﬀ )  Step 1: For all i, fi (θ(i)) − fi (θoﬀ ) ≤ (cid:107)θ(i)−θoﬀ (cid:107)2  2−(cid:107)θ(i+1)−θoﬀ (cid:107)2 2η  2  + ηG 2  2 =⇒  (cid:107)θ(i) − θoﬀ (cid:107)2  2 − (cid:107)θ(i+1) − θoﬀ (cid:107)2  2  2η  i=1  (cid:107)θ(1) − θoﬀ (cid:107)2  2 − (cid:107)θ(t+1) − θoﬀ (cid:107)2 2η  2  = ≤ R 2/(2η) + tηG 2/2 = RG  √  t  +  t · ηG 2  + 2 t · ηG 2  2  14  

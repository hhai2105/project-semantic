compsci 514: algorithms for data science  Andrew McGregor  Lecture 3  0  
last time  Last Class We Covered: • Markov’s inequality: the most fundamental concentration bound. • Algorithmic applications of Markov’s inequality, linearity of  expectation, and indicator random variables: • Counting collisions to estimate CAPTCHA database size. • Counting collisions to understand the runtime of hash tables with  random hash functions.  1  
last time  Last Class We Covered: • Markov’s inequality: the most fundamental concentration bound. • Algorithmic applications of Markov’s inequality, linearity of  expectation, and indicator random variables: • Counting collisions to estimate CAPTCHA database size. • Counting collisions to understand the runtime of hash tables with  random hash functions.  • Collision counting is closely related to the birthday paradox.  1  
today  Today: • Finish up random hash functions and hash tables. • See an application of random hashing to load balancing in  distributed systems.  • Through this application learn about:  • Chebyshev’s inequality, which strengthens Markov’s inequality. • The union bound, for understanding the probabilities of correlated  random events.  2  
two level hashing  Want to preserve O(1) query time while using O(m) space.  3  
two level hashing  Want to preserve O(1) query time while using O(m) space.  Two-Level Hashing:  3  
two level hashing  Want to preserve O(1) query time while using O(m) space.  Two-Level Hashing:  • For each bucket with si values, pick a collision free hash function  mapping [si ] → [s 2 i ].  3  
two level hashing  Want to preserve O(1) query time while using O(m) space.  Two-Level Hashing:  • For each bucket with si values, pick a collision free hash function  mapping [si ] → [s 2 i ].  • Just Showed: A random function is collision free with probability ≥ 7 8 so can just generate a random hash function and check if it is collision free.  3  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions.  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: S = n +(cid:80)n  i=1 s2 i  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  E[s2 i ]  i=1  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  E[s2 i ]  i=1  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  E[s2 i ]  i=1  E[s2  i ] = E  Ih(xj )=i    m(cid:88)  j=1  2  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  E[s2 i ]  i=1  2  Ih(xj )=i    m(cid:88)  (cid:88)  j=1  j,k∈[m]  E[s2  i ] = E  = E    Ih(xj )=i · Ih(xk )=i  Collisions again!  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  =    m(cid:88)  (cid:88)  Ih(xj )=i · Ih(xk )=i  2  E[s2  i ] = E  = E  Ih(xj )=i  j=1  j,k∈[m]  E[s2 i ]  i=1  (cid:88)  j,k∈[m]  E(cid:2)Ih(xj )=i · Ih(xk )=i  (cid:3) .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  =    m(cid:88)  (cid:88)  Ih(xj )=i · Ih(xk )=i  2  E[s2  i ] = E  = E  Ih(xj )=i  j=1  j,k∈[m]  E[s2 i ]  i=1  (cid:88)  j,k∈[m]  E(cid:2)Ih(xj )=i · Ih(xk )=i  (cid:3) .  • For j = k,  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2 i ]  i=1  E[s2  i ] = E  Ih(xj )=i  2  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:1)2(cid:105) (cid:3) = E(cid:104)(cid:0)Ih(xj )=i  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i    m(cid:88)  (cid:88)  j=1  Ih(xj )=i · Ih(xk )=i  = E  j,k∈[m]  j,k∈[m]  (cid:3) .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2  i ] = E  Ih(xj )=i  2  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:1)2(cid:105) (cid:3) = E(cid:104)(cid:0)Ih(xj )=i  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i    m(cid:88)  (cid:88)  j=1  Ih(xj )=i · Ih(xk )=i  = Pr[h(xj ) = i]  = E  j,k∈[m]  j,k∈[m]  E[s2 i ]  i=1  (cid:3) .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2 i ]  i=1  E[s2  i ] = E  Ih(xj )=i  2  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:1)2(cid:105) (cid:3) = E(cid:104)(cid:0)Ih(xj )=i  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i    m(cid:88)  (cid:88)  j=1  Ih(xj )=i · Ih(xk )=i  = E  j,k∈[m]  j,k∈[m]  (cid:3) .  = Pr[h(xj ) = i] = 1 n .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2 i ]  i=1  E[s2  i ] = E  Ih(xj )=i  2  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:1)2(cid:105) (cid:3) = E(cid:104)(cid:0)Ih(xj )=i  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i    m(cid:88)  (cid:88)  j=1  Ih(xj )=i · Ih(xk )=i  = E  j,k∈[m]  j,k∈[m]  (cid:3) .  = Pr[h(xj ) = i] = 1 n .  • For j (cid:54)= k,  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2  i ] = E  Ih(xj )=i  E[s2 i ]  i=1  2    m(cid:88)  (cid:88)  j=1  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i Ih(xj )=i · Ih(xk )=i (cid:3) = E(cid:104)(cid:0)Ih(xj )=i (cid:1)2(cid:105) (cid:3)  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  (cid:3) .  = E  j,k∈[m]  j,k∈[m]  = Pr[h(xj ) = i] = 1 n .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2 i ]  i=1  E[s2  i ] = E  Ih(xj )=i  2    m(cid:88)  (cid:88)  j=1  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:3) = E(cid:104)(cid:0)Ih(xj )=i (cid:1)2(cid:105) (cid:3) = Pr[h(xj ) = i ∩ h(xk ) = i]  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  Ih(xj )=i · Ih(xk )=i  = E  j,k∈[m]  j,k∈[m]  (cid:3) .  = Pr[h(xj ) = i] = 1 n .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2  i ] = E  Ih(xj )=i  2    m(cid:88)  (cid:88)  j=1  Query time for two level hashing is O(1): requires evaluating two hash functions. What is the expected space usage?  Up to constants, space used is: E[S] = n +(cid:80)n  = (cid:88) E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:3) = E(cid:104)(cid:0)Ih(xj )=i (cid:1)2(cid:105) (cid:3) = Pr[h(xj ) = i ∩ h(xk ) = i] = 1  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  Ih(xj )=i · Ih(xk )=i  = E  j,k∈[m]  (cid:3) .  n2 .  E[s2 i ]  i=1  j,k∈[m]  = Pr[h(xj ) = i] = 1 n .  xj , xk : stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored in hash table at position i.  4  
space usage  E[s2  i ] =  (cid:88)  j,k∈[m]  E(cid:2)Ih(xj )=i · Ih(xk )=i  (cid:3)  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  (cid:3) = 1 (cid:3) = 1  n . n2 .  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  (cid:88)  E[s2  i ] =  j,k∈[m] = m · 1 n  + 2 ·  2  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  · 1 n2  n . n2 .  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  (cid:88)  E[s2  i ] =  j,k∈[m] = m · 1 n  + 2 ·  2  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  · 1 n2  n . n2 .  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  (cid:88)  E[s2  i ] =  j,k∈[m] = m · 1 n  + 2 ·  2  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  · 1 n2  n . n2 .  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  E[s2  i ] =  (cid:88)  j,k∈[m] = m · 1 n  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  + 2 · 2 m(m − 1)  · 1 n2  n . n2 .  n2  m n  +  =  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  m n  +  =  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i  ≤ 2 (If we set n = m.)  E[s2  i ] =  (cid:88)  j,k∈[m] = m · 1 n  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  + 2 · 2 m(m − 1)  · 1 n2  n . n2 .  n2  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  E[s2  i ] =  (cid:88)  j,k∈[m] = m · 1 n  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  + 2 · 2 m(m − 1)  · 1 n2  n . n2 .  n2  ≤ 2 (If we set n = m.)  m n  +  =  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i n(cid:88)  E[S] = n +  E[s2 i ]  Total Expected Space Usage: (if we set n = m)  i=1  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  E[s2  i ] =  (cid:88)  j,k∈[m] = m · 1 n  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  + 2 · 2 m(m − 1)  · 1 n2  n . n2 .  n2  m n  +  =  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i n(cid:88)  E[S] = n +  ≤ 2 (If we set n = m.)  Total Expected Space Usage: (if we set n = m)  E[s2  i ] ≤ n + n · 2 = 3n = 3m.  i=1  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
space usage  E[s2  i ] =  (cid:88)  j,k∈[m] = m · 1 n  (cid:3)  (cid:19)  E(cid:2)Ih(xj )=i · Ih(xk )=i (cid:18)m (cid:3) = 1 (cid:3) = 1  + 2 · 2 m(m − 1)  · 1 n2  n . n2 .  n2  m n  +  =  • For j = k, E(cid:2)Ih(xj )=i · Ih(xk )=i • For j (cid:54)= k, E(cid:2)Ih(xj )=i · Ih(xk )=i n(cid:88)  E[S] = n +  ≤ 2 (If we set n = m.)  Total Expected Space Usage: (if we set n = m)  E[s2  i ] ≤ n + n · 2 = 3n = 3m.  Near optimal space with O(1) query time!  i=1  xj , xk : stored items, m: # stored items, n: hash table size, h: random hash function, S: space usage of two level hashing, si : # items stored at pos i.  5  
efficiently computable hash function  So Far: we have assumed a fully random hash function h(x) with Pr[h(x) = i] = 1 for x (cid:54)= y .  n for i ∈ 1, . . . , n and h(x), h(y ) independent  6  
efficiently computable hash function  n for i ∈ 1, . . . , n and h(x), h(y ) independent  So Far: we have assumed a fully random hash function h(x) with Pr[h(x) = i] = 1 for x (cid:54)= y . • To compute a random hash function we have to store a table of x values and their hash values. Would take at least O(m) space and O(m) query time if we hash m values. Making our whole quest for O(1) query time pointless!  6  
efficiently computable hash functions  What properties did we use of the randomly chosen hash function?  7  
efficiently computable hash functions  What properties did we use of the randomly chosen hash function?  2-Universal Hash Function (low collision probability). A random hash function from h : U → [n] is two universal if:  Pr[h(x) = h(y )] ≤ 1 n  .  7  
efficiently computable hash functions  What properties did we use of the randomly chosen hash function?  2-Universal Hash Function (low collision probability). A random hash function from h : U → [n] is two universal if:  Pr[h(x) = h(y )] ≤ 1 n  .  Exercise: Rework the two level hashing proof to show that this property is really all that is needed.  7  
efficiently computable hash functions  What properties did we use of the randomly chosen hash function?  2-Universal Hash Function (low collision probability). A random hash function from h : U → [n] is two universal if:  Pr[h(x) = h(y )] ≤ 1 n  .  Exercise: Rework the two level hashing proof to show that this property is really all that is needed.  When h(x) and h(y ) are chosen independently at random from [n], Pr[h(x) = h(y )] = 1 n (so a fully random hash function is 2-universal)  7  
efficiently computable hash functions  What properties did we use of the randomly chosen hash function?  2-Universal Hash Function (low collision probability). A random hash function from h : U → [n] is two universal if:  Pr[h(x) = h(y )] ≤ 1 n  .  Exercise: Rework the two level hashing proof to show that this property is really all that is needed.  When h(x) and h(y ) are chosen independently at random from [n], Pr[h(x) = h(y )] = 1 n (so a fully random hash function is 2-universal) Eﬃcient Alternative: Let p be a prime with p ≥ |U|. Choose random a, b ∈ [p] with a (cid:54)= 0. Let:  h(x) = (ax + b mod p) mod n.  7  
pairwise independence  Another common requirement for a hash function:  8  
pairwise independence  Another common requirement for a hash function:  Pairwise Independent Hash Function. A random hash function from h : U → [n] is pairwise independent if for all i, j ∈ [n]:  Pr[h(x) = i ∩ h(y ) = j] =  1 n2 .  8  
pairwise independence  Another common requirement for a hash function:  Pairwise Independent Hash Function. A random hash function from h : U → [n] is pairwise independent if for all i, j ∈ [n]:  Pr[h(x) = i ∩ h(y ) = j] =  1 n2 .  Breakout: Which is a more stringent requirement? 2-universal or pairwise independent?  8  
pairwise independence  Another common requirement for a hash function:  Pairwise Independent Hash Function. A random hash function from h : U → [n] is pairwise independent if for all i, j ∈ [n]:  Pr[h(x) = i ∩ h(y ) = j] =  1 n2 .  Breakout: Which is a more stringent requirement? 2-universal or pairwise independent?  Pr[h(x) = h(y )] =  n(cid:88)  i=1  Pr[h(x) = i ∩ h(y ) = i] = n · 1  n2 =  1 n  .  8  
pairwise independence  Another common requirement for a hash function:  Pairwise Independent Hash Function. A random hash function from h : U → [n] is pairwise independent if for all i, j ∈ [n]:  Pr[h(x) = i ∩ h(y ) = j] =  1 n2 .  Breakout: Which is a more stringent requirement? 2-universal or pairwise independent?  n(cid:88)  i=1  Pr[h(x) = h(y )] =  Pr[h(x) = i ∩ h(y ) = i] = n · 1  n2 =  1 n  .  A closely related (ax + b) mod p construction gives pairwise  independence on top of 2-universality.  8  
pairwise independence  Another common requirement for a hash function:  Pairwise Independent Hash Function. A random hash function from h : U → [n] is pairwise independent if for all i, j ∈ [n]:  Pr[h(x) = i ∩ h(y ) = j] =  1 n2 .  Breakout: Which is a more stringent requirement? 2-universal or pairwise independent?  n(cid:88)  i=1  Pr[h(x) = h(y )] =  Pr[h(x) = i ∩ h(y ) = i] = n · 1  n2 =  1 n  .  A closely related (ax + b) mod p construction gives pairwise  independence on top of 2-universality.  Remember: A fully random hash function is both 2-universal and pairwise independent. But it is not eﬃciently implementable.  8  
next step  1. We’ll consider an application where our toolkit of linearity of expectation + Markov’s inequality doesn’t give much.  9  
next step  1. We’ll consider an application where our toolkit of linearity of expectation + Markov’s inequality doesn’t give much.  2. Then we’ll show how a simple twist on Markov’s can give a much stronger result.  9  
another application  Randomized Load Balancing:  10  
another application  Randomized Load Balancing:  Simple Model: n requests randomly assigned to k servers. How many requests must each server handle?  10  
another application  Randomized Load Balancing:  Simple Model: n requests randomly assigned to k servers. How many requests must each server handle?  10  
weakness of markov’s  Expected Number of requests assigned to server i:  E[Ri ] =  E[Irequest j assigned to i ] =  j=1  j=1  n(cid:88)  n(cid:88)  Pr [j assigned to i] =  n k  .  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  11  
weakness of markov’s  Expected Number of requests assigned to server i:  E[Ri ] =  E[Irequest j assigned to i ] =  j=1  j=1  n(cid:88)  n(cid:88)  Pr [j assigned to i] =  n k  .  If we provision each server be able to handle twice the expected load, what is the probability that a server is overloaded?  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  11  
weakness of markov’s  Expected Number of requests assigned to server i:  E[Ri ] =  E[Irequest j assigned to i ] =  j=1  j=1  n(cid:88)  n(cid:88)  Pr [j assigned to i] =  n k  .  If we provision each server be able to handle twice the expected load, what is the probability that a server is overloaded?  Applying Markov’s Inequality  Pr [Ri ≥ 2E[Ri ]] ≤ E[Ri ] 2E[Ri ]  =  1 2  .  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  11  
weakness of markov’s  Expected Number of requests assigned to server i:  E[Ri ] =  E[Irequest j assigned to i ] =  j=1  j=1  n(cid:88)  n(cid:88)  Pr [j assigned to i] =  n k  .  If we provision each server be able to handle twice the expected load, what is the probability that a server is overloaded?  Applying Markov’s Inequality  Pr [Ri ≥ 2E[Ri ]] ≤ E[Ri ] 2E[Ri ]  =  1 2  .  Not great...half the servers may be overloaded.  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  11  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  X2 is a nonnegative random variable. So can apply Markov’s  inequality:  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  X2 is a nonnegative random variable. So can apply Markov’s  inequality:  Pr(X2 ≥ t2) ≤ E[X2]  t2  .  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  X2 is a nonnegative random variable. So can apply Markov’s  inequality:  Pr(|X| ≥ t) = Pr(X2 ≥ t2) ≤ E[X2]  t2  .  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  X2 is a nonnegative random variable. So can apply Markov’s  inequality:  Chebyshev’s inequality:  Pr(|X| ≥ t) = Pr(X2 ≥ t2) ≤ E[X2]  t2  .  12  
chebyshev’s inequality  With a very simple twist Markov’s Inequality can be made much more powerful.  For any random variable X and any value t > 0: Pr(|X| ≥ t) = Pr(X2 ≥ t2).  X2 is a nonnegative random variable. So can apply Markov’s  inequality:  Chebyshev’s inequality:  Pr(|X − E[X]| ≥ t) ≤ Var[X] (by plugging in the random variable X − E[X])  t2  .  12  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  n(cid:88)  Ri =  Ri,j  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  j=1  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  n(cid:88)  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  j=1  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  n(cid:88)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  Var[Ri,j ] = E(cid:104)  j=1  (Ri,j − E[Ri,j ])2(cid:105)  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  n(cid:88)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  Var[Ri,j ] = E(cid:104)  j=1  (Ri,j − E[Ri,j ])2(cid:105)  = Pr(Ri,j = 1) · (1 − E[Ri,j ])2 + Pr(Ri,j = 0) · (0 − E[Ri,j ])2  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  n(cid:88)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  Var[Ri,j ] = E(cid:104)  j=1  (Ri,j − E[Ri,j ])2(cid:105) (cid:18) (cid:18)  (cid:19)2  = Pr(Ri,j = 1) · (1 − E[Ri,j ])2 + Pr(Ri,j = 0) · (0 − E[Ri,j ])2  (cid:19)  (cid:18)  (cid:19)2  ·  =  1 k  1 − 1 k  +  1 − 1 k  ·  0 − 1 k  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  n(cid:88)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  Var[Ri,j ] = E(cid:104)  j=1  (Ri,j − E[Ri,j ])2(cid:105) (cid:18) (cid:18)  (cid:19)2  +  =  =  1 k 1 k  ·  1 − 1 k − 1 k 2 ≤ 1  k  = Pr(Ri,j = 1) · (1 − E[Ri,j ])2 + Pr(Ri,j = 0) · (0 − E[Ri,j ])2  (cid:19)  (cid:18)  (cid:19)2  1 − 1 k  ·  0 − 1 k  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
load balancing variance  We can write the number of requests assigned to server i, Ri as:  Var[Ri ] =  Var[Ri,j ]  (linearity of variance)  n(cid:88)  where Ri,j is 1 if request j is assigned to server i and 0 otherwise.  Var[Ri,j ] = E(cid:104)  j=1  (Ri,j − E[Ri,j ])2(cid:105) (cid:18) (cid:18)  (cid:19)2  +  =  =  1 k 1 k  ·  1 − 1 k − 1 k 2 ≤ 1  k  (cid:19)  (cid:18)  (cid:19)2  1 − 1 k  ·  0 − 1 k  =⇒ Var[Ri ] ≤ n k  .  = Pr(Ri,j = 1) · (1 − E[Ri,j ])2 + Pr(Ri,j = 0) · (0 − E[Ri,j ])2  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  13  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k .  k  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k . Applying Chebyshev’s: ≤ Pr  (cid:16)|Ri − E[Ri ]| ≥ n  (cid:18)  (cid:19)  Pr  Ri ≥ 2n k  k  (cid:17)  k  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k . Applying Chebyshev’s: ≤ Pr  (cid:16)|Ri − E[Ri ]| ≥ n  (cid:17) ≤ n/k  (cid:18)  k  (cid:19)  Pr  Ri ≥ 2n k  k  n2/k 2  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k . Applying Chebyshev’s: ≤ Pr  (cid:16)|Ri − E[Ri ]| ≥ n  (cid:17) ≤ n/k  (cid:18)  (cid:19)  k  Pr  Ri ≥ 2n k  n2/k 2 =  k n  .  k  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k . Applying Chebyshev’s: ≤ Pr  (cid:16)|Ri − E[Ri ]| ≥ n  (cid:17) ≤ n/k  (cid:18)  (cid:19)  k  Pr  Ri ≥ 2n k  n2/k 2 =  k n  .  k  • Overload probability is extremely small when k (cid:28) n!  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
bounding the load via chebyshevs  Letting Ri be the number of requests sent to server i, E[Ri ] = n and Var[Ri ] ≤ n k . Applying Chebyshev’s: ≤ Pr  (cid:16)|Ri − E[Ri ]| ≥ n  (cid:17) ≤ n/k  (cid:18)  (cid:19)  k  Pr  Ri ≥ 2n k  n2/k 2 =  k n  .  k  • Overload probability is extremely small when k (cid:28) n! • Might seem counterintuitive – bound gets worse as k grows. • When k is large, the number of requests each server sees in expectation is very small so the law of large numbers doesn’t ‘kick in’.  n: total number of requests, k: number of servers randomly assigned requests, Ri : number of requests assigned to server i.  14  
